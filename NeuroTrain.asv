% Solve an Input-Output Fitting problem with a Neural Network
% Script generated by Neural Fitting app
% Created 27-Jul-2016 16:27:36
%
% This script assumes these variables are defined:
%
%   engineInputs - input data.
%   engineTargets - target data.
%
%Подбираем наилучшее кол-во нейронов. Для оценки используем регрессию.

x = engineInputs;
t = engineTargets;

% Choose a Training Function
% For a list of all training functions type: help nntrain
% 'trainlm' is usually fastest.
% 'trainbr' takes longer but may be better for challenging problems.
% 'trainscg' uses less memory. Suitable in low memory situations.
trainFcn = 'trainlm';  % Levenberg-Marquardt backpropagation.

% Create a Fitting Network
hiddenLayerSize = 10;
net = fitnet(hiddenLayerSize,trainFcn);
% Two (or more) layer fitting networks can fit any finite input-output
%    relationship arbitrarily well given enough hidden neurons.
%    fitnet(hiddenSizes,trainFcn) takes a row vector of N hidden layer
%    sizes, and a backpropagation training function, and returns
%    a feed-forward neural network with N+1 layers.
%    Input, output and output layers sizes are set to 0.  These sizes will
%    automatically be configured to match particular data by train. Or the
%    user can manually configure inputs and outputs with configure.

%2-х- или более слойные сети могут быть подогнаны под любое конечное
%отношение вх/вых, произвольно данное достаточному кол-ву нейронов.
%fitnet(hiddenSizes,trainFcn) приним. строку-вектор N размеров скрытых
%слоёв, тренировочную ф-цию обратно распространяемой ошибки и возвр. сеть с прямой передачей с N+1 скрытыми слоями.
%Размеры вх, вых, вых слоя уст. в 0. Их размеры подберутся ф-цией трени автоматически.

% Choose Input and Output Pre/Post-Processing Functions
% For a list of all processing functions type: help nnprocess
net.input.processFcns = {'removeconstantrows','mapminmax'};
net.output.processFcns = {'removeconstantrows','mapminmax'};
%'removeconstantrows' - удалить строки м-цы, содер-щие значение
%'mapminmax' - привести минимальное и максимальное значение к [-1;1]

% Setup Division of Data for Training, Validation, Testing
% For a list of all data division functions type: help nndivide
net.divideFcn = 'dividerand';  % Divide data randomly
net.divideMode = 'sample';  % Divide up every sample
net.divideParam.trainRatio = 70/100;
net.divideParam.valRatio = 15/100;
net.divideParam.testRatio = 15/100;

% Choose a Performance Function
% For a list of all performance functions type: help nnperformance
net.performFcn = 'mse';  % Mean Squared Error

% Choose Plot Functions
% For a list of all plot functions type: help nnplot
net.plotFcns = {'plotperform','plottrainstate','ploterrhist', ...
    'plotregression', 'plotfit'};

% Train the Network
[net,tr] = train(net,x,t);
%берём сеть net, вх. данн. x, цель t и возвр. сеть net и тренировочную
%запись tr. Могут передаваться нач. вх. сост. и нач. слои (Xi, Ai), веса ошибок EW.

% Test the Network
y = net(x);
e = gsubtract(t,y);
%Вычисление ошибки. gsubtract - поэлементное вычитание.
performance = perform(net,t,y)
%Вычисление производительности сети

% Recalculate Training, Validation and Test Performance
%tr - структура с параметрами сети, обучения и показателями обучения, как градиент ф-ции ошибки и др.
trainTargets = t .* tr.trainMask{1};
valTargets = t .* tr.valMask{1};
testTargets = t .* tr.testMask{1};
trainPerformance = perform(net,trainTargets,y)
valPerformance = perform(net,valTargets,y)
testPerformance = perform(net,testTargets,y)

% View the Network
view(net)

% Plots
% Uncomment these lines to enable various plots.
%figure, plotperform(tr)
%figure, plottrainstate(tr)
%figure, ploterrhist(e)
%figure, plotregression(t,y)
%figure, plotfit(net,x,t)

% Deployment
% Change the (false) values to (true) to enable the following code blocks.
% See the help for each generation function for more information.
if (false)
    % Generate MATLAB function for neural network for application
    % deployment in MATLAB scripts or with MATLAB Compiler and Builder
    % tools, or simply to examine the calculations your trained neural
    % network performs.
    genFunction(net,'myNeuralNetworkFunction');
    y = myNeuralNetworkFunction(x);
end
if (false)
    % Generate a matrix-only MATLAB function for neural network code
    % generation with MATLAB Coder tools.
    genFunction(net,'myNeuralNetworkFunction','MatrixOnly','yes');
    y = myNeuralNetworkFunction(x);
end
if (false)
    % Generate a Simulink diagram for simulation or deployment with.
    % Simulink Coder tools.
    gensim(net);
end

%Создаём ф-цию сети.
genFunction(net,'NNFun','MatrixOnly','yes');
y = NNFun(x);
%Строим регрессию - основной показатель качества
[R,M,B] = regression(t,y)
plotregression(t,y)

exit=false;
inc=-1; %Переменная, с пом. к-рой изменяем число нейронов: пробуем уменьшить, затем увеличить их число.
R_nes=1; %Необходимый показатель: По его достижении цикл завершается. Если 1, то ищем максимум.
i=1;
while (~exit)
   hiddenLayerSize=hiddenLayerSize+inc;
   i=i+1;
   net = fitnet(hiddenLayerSize,trainFcn);
   [net,tr] = train(net,x,t);
   [R_cur,M,B] = regression(t,y);
   R_c=mean(R_cur); %R_cur - многомерный пар-р, число измерений соотв. числу пар-ров.
   R=[R R_c]; %Добавляем рез-т в массив
   if R_c>=R_nes exit=true; end %Если достигли нужного значения - выходим.
   if R_c<R(i-1)
       if inc==1 exit=true; end %Если inc=-1, то мы пробовали уменьшать, если inc=1, значит нашли максимальное кол-во нейр.
       inc=1;
   end
end
[mv,mi]=max(R);